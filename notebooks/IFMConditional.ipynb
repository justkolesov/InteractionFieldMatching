{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d9c82ff",
   "metadata": {},
   "source": [
    "## IFM: Conditional Generation CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231814d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#import wandb\n",
    "import sys\n",
    "sys.path.append(\"/trinity/home/a.kolesov/EFM/\")\n",
    "from src.models import DDPM, ExponentialMovingAverage\n",
    "from src.ifm_field import IFM\n",
    "from src.utils import Config, optimization_manager, random_color"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708dbd04",
   "metadata": {},
   "source": [
    "## 1. Base Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98cfa7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config()\n",
    "\n",
    " \n",
    "config.L = 20. # important parameter\n",
    "config.SCALE = 1.\n",
    "config.K =  math.pi/config.L\n",
    "config.D = math.pi/(2*config.K)\n",
    "config.device = 'cuda'\n",
    "config.experiment = 'generation'\n",
    "\n",
    "config.data = Config()\n",
    "config.data.name = 'CIFAR10'\n",
    "config.data.num_channels = 3\n",
    "config.data.img_resize = 32\n",
    "config.data.image_size=32\n",
    "config.data.centered = True\n",
    "config.DIM = config.data.num_channels*config.data.image_size*config.data.image_size + 1\n",
    "\n",
    "config.p = Config()\n",
    "config.p.x_loc = 0.\n",
    "\n",
    "config.q = Config()\n",
    "config.q.x_loc = config.L\n",
    "\n",
    "config.training = Config()\n",
    "config.training.small_batch_size =64 # important parameter\n",
    "config.training.batch_size =256      # important parameter\n",
    "config.training.field_type = \"Shifted\"\n",
    "config.training.plan_type = \"Independent\"\n",
    "config.training.field_form = \"exponential\"\n",
    "config.training.n_iters = 1_000_000\n",
    "config.training.sde = 'poisson'\n",
    "config.training.eval_freq = 1_000\n",
    "config.training.snapshot_freq = 5_000\n",
    "config.training.sigma_end = 0.1\n",
    "config.training.M = 191 # important parameter\n",
    "config.training.tau = 0.03  \n",
    "config.training.epsilon = 1e-3 # important parameter\n",
    "config.training.interpolation = 'Uniform'\n",
    "config.training.noised_interpolation=False\n",
    "config.training.restrict_M = False\n",
    "config.training.gamma = 5. # important parameter\n",
    "\n",
    "config.model  = Config()\n",
    "config.model.name = 'ncsnpp'\n",
    "config.model.scale_by_sigma = False\n",
    "config.model.ema_rate = 0.9999\n",
    "config.model.normalization = 'GroupNorm'\n",
    "config.model.nonlinearity = 'swish'\n",
    "config.model.nf = 128\n",
    "config.model.ch_mult = (1, 2, 2, 2)\n",
    "config.model.num_res_blocks = 4\n",
    "config.model.attn_resolutions = (16,)\n",
    "config.model.resamp_with_conv = True\n",
    "config.model.conditional = True\n",
    "config.model.fir = False\n",
    "config.model.fir_kernel = [1, 3, 3, 1]\n",
    "config.model.skip_rescale = True\n",
    "config.model.resblock_type = 'biggan'\n",
    "config.model.progressive = 'none'\n",
    "config.model.progressive_input = 'none'\n",
    "config.model.progressive_combine = 'sum'\n",
    "config.model.attention_type = 'ddpm'\n",
    "config.model.init_scale = 0.\n",
    "config.model.fourier_scale = 16\n",
    "config.model.embedding_type = 'positional'\n",
    "config.model.conv_size = 3\n",
    "config.model.dropout = 0.1\n",
    "config.model.num_classes = 10\n",
    "config.model.class_cond = True\n",
    "\n",
    "config.optim  = Config()\n",
    "config.optim.weight_decay = 0\n",
    "config.optim.optimizer = 'Adam'\n",
    "config.optim.lr = 2e-4\n",
    "config.optim.beta1 = 0.9\n",
    "config.optim.eps = 1e-8 \n",
    "config.optim.warmup = 5000  \n",
    "config.optim.grad_clip = 1.\n",
    "\n",
    "config.ode = Config()\n",
    "config.ode.gamma = 1e-7\n",
    "config.ode.step = 0.25\n",
    "\n",
    "config.sampling = Config()\n",
    "config.sampling.method = 'ode'\n",
    "config.sampling.ode_solver = 'rk45'\n",
    "config.sampling.N = 100\n",
    "config.sampling.z_max = config.L# - config.training.epsilon\n",
    "config.sampling.z_min = config.training.epsilon\n",
    "config.sampling.upper_norm = 3000\n",
    "config.sampling.z_exp=1\n",
    "config.sampling.vs = False\n",
    "config.sampling.visual_iterations=10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdaef2a8",
   "metadata": {},
   "source": [
    "## 2. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c62e6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSFORM = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(config.data.img_resize),\n",
    "    torchvision.transforms.ToTensor()\n",
    "])\n",
    "\n",
    "\n",
    "train_data = torchvision.datasets.CIFAR10(root='/trinity/home/a.kolesov/data/CIFAR10/',\n",
    "                                        train=True, download=True, transform=TRANSFORM)\n",
    "eval_data = torchvision.datasets.CIFAR10(root='/trinity/home/a.kolesov/data/CIFAR10/',\n",
    "                                        train=False, download=True, transform=TRANSFORM)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=config.training.batch_size,\n",
    "                                           shuffle=True)\n",
    "eval_loader =  torch.utils.data.DataLoader(eval_data, batch_size=config.training.batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "train_iter = iter(train_loader)\n",
    "eval_iter = iter(eval_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814502aa",
   "metadata": {},
   "source": [
    "## 3. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ed82c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = DDPM(config).to(config.device)\n",
    "params = net.parameters()\n",
    "optimizer = torch.optim.Adam(params,\n",
    "                       lr=config.optim.lr, betas=(config.optim.beta1, 0.999), eps=config.optim.eps,\n",
    "                       weight_decay=config.optim.weight_decay)\n",
    "\n",
    "ema = ExponentialMovingAverage(net.parameters(), decay=config.model.ema_rate)\n",
    "state = dict(optimizer=optimizer, model=net, ema=ema, step=0)\n",
    "optimize_fn = optimization_manager(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc93824",
   "metadata": {},
   "source": [
    "## 4. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f38449",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.name_exp = f\"Cond_CIFAR10Generation_L={config.L}_sc={config.SCALE}_BS_{config.training.batch_size}_\\\n",
    "SBS={config.training.small_batch_size}_plan_{config.training.plan_type}_\\\n",
    "Int={config.training.interpolation}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842cf0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "ifm = IFM(config)\n",
    "net, state = ifm.train(train_loader, eval_loader,\n",
    "                       net, optimizer, optimize_fn,\n",
    "                       state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5199f677",
   "metadata": {},
   "source": [
    "## 5. Sampling for conditional model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39540f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearnedImageODESolver:\n",
    "\n",
    "    def __init__(self, net, config,cls=None):\n",
    "        self.config = config\n",
    "        self.net = net\n",
    "        self.cls = cls\n",
    "\n",
    "    def __call__(self, x_init ):\n",
    "        \n",
    "        if self.config.model.class_cond:\n",
    "            #class_labels = torch.arange(10).to(self.config.device)\n",
    "            class_labels = torch.tensor([self.cls]).repeat(x_init.shape[0],).to(self.config.device)\n",
    "        \n",
    "        \n",
    "        trajectory = [x_init[:,1:].view(-1,self.config.data.num_channels,\n",
    "                                               self.config.data.image_size,\n",
    "                                               self.config.data.image_size).clone().detach().cpu()]\n",
    "        mask = torch.tensor(x_init.shape[0]*[True]).to(self.config.device)\n",
    "        \n",
    "        while mask.any():\n",
    " \n",
    "            if self.config.model.class_cond:\n",
    "        \n",
    "                field_x, field_z = self.net(x_init[:,1:].view(-1,self.config.data.num_channels,\n",
    "                                                             self.config.data.image_size,\n",
    "                                                             self.config.data.image_size) , x_init[:,0] , class_labels  )\n",
    "            \n",
    "            else:\n",
    "                field_x, field_z = self.net(x_init[:,1:].view(-1,self.config.data.num_channels,\n",
    "                                                             self.config.data.image_size,\n",
    "                                                             self.config.data.image_size) , x_init[:,0]   )\n",
    "            \n",
    "            \n",
    "            field = torch.cat([field_z.view(-1,1),\n",
    "                               field_x.view(-1, self.config.data.num_channels*\\\n",
    "                                                self.config.data.image_size*\\\n",
    "                                                self.config.data.image_size)], dim=1) # [B, 1+C*H*W]\n",
    "            \n",
    "            # backward\n",
    "            x_init  = x_init  - (self.config.ode.step/ ( field_z.view(-1,1)  + self.config.ode.gamma ))*field # [B, C*H*W+1]\n",
    "            trajectory.append(x_init[:,1:].view(-1,self.config.data.num_channels,\n",
    "                                               self.config.data.image_size,\n",
    "                                               self.config.data.image_size).clone().detach().cpu())\n",
    "            t = x_init[:,0]\n",
    "            mask = t[0] > self.config.training.epsilon\n",
    "            #mask = t[0] < self.config.L - self.config.training.epsilon\n",
    "          \n",
    "            \n",
    "            \n",
    "            \n",
    "        return x_init, trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214a5c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    path=\"/trinity/home/a.kolesov/EFM/ckpt/generation/CIFAR10/Cond_CIFAR10Generation_L=20.0_sc=1.0_BS_256_SBS=64_plan_Independent_Int=Uniform.pth\"\n",
    "    net.load_state_dict(torch.load(path))\n",
    "    net = net.to(config.device)\n",
    "    \n",
    "    \n",
    "    shape = (256, config.data.num_channels,\n",
    "            config.data.image_size, config.data.image_size)\n",
    "    batch_y = torch.randn(*shape).to(config.device)\n",
    "    \n",
    "     \n",
    "    ode_solver = LearnedImageODESolver(net , config, cls = 0)\n",
    "    \n",
    "    start = time.time()\n",
    "    sample, traj = ode_solver(torch.cat([(config.L)*torch.ones(batch_y.shape[0],\n",
    "                              device=batch_y.device)[:,None],\n",
    "                              batch_y.view(-1, config.DIM-1)],dim=1).to(config.device))\n",
    "    print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bacd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(10,10,figsize=(9.6,10),dpi=500)\n",
    "for idx in range(10):\n",
    "    for jdx in range(10):\n",
    "        ax[0,jdx].set_title(f\"c={jdx}\",fontsize=17)\n",
    "        ax[idx,jdx].imshow(sample[jdx,idx].permute(1,2,0))\n",
    "        ax[idx,jdx].set_xticks([])\n",
    "        ax[idx,jdx].set_yticks([])\n",
    "fig.tight_layout(pad=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58944ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
